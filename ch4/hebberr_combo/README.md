Back to [All Sims](https://github.com/CompCogNeuro/sims) (also for general info and executable downloads)

# Introduction

The previous  `err_driven_hidden` project showed that error-driven learning with a hidden layer is needed to solve difficult problems. This simulation shows the complementary advantages of hebbian learning when combined with error driven learning to support generalization. 
 

In this project we have expanded the size of all layers to accommodate a richer set of inputs, specifically those that involve the same combinations of horizontal and vertical lines that we saw in `self_org`. In this case however we are asking the network to label the lines in the output layer, which it has to learn. The first column of output units corresponds to the vertical lines, and the second column corresponds to the horizontal lines. For example, the event V0_H1, which is the leftmost vertical line combined with the second horizontal line from the bottom of horizontal, has an output layer target of the bottom unit on the left side for V0 and the second from bottom unit on the right side for H1). Click on `Lines2` to familiarize yourself with these patterns.  

* Click `Init` and `Step Trial` to see one of the patterns presented to the network. You should see the correct target in the output layer at the end of the trial as the network is using error-driven learning to clamp on that target. If you then click on `ActM` instead of `Act` in the Netview you will see what the network 'guessed' for the labels in the minus phase, before it was told what the correct labels were.   

* Click `Train`, and then switch to  `TrnEpcPlot` to view the SSE error  over epochs of training. You should see that the SSE goes down to zero within a few epochs as the network learns to label the different combination of lines using pure Error Driven learning. You can switch to Netview and step through a few trials looking at ActM to convince yourself that it has really learned these. Click `r.Wt` and look at a few of the hidden units to see whether they learn systematic representations.

> **Question 4.10:**  Do the hidden units learn to represent the individual lines like they did in `self_org`? Why or why not? Explain in terms of how the learning rule is designed to adjust weights when minimizing error.

* For this project we have not actually given the network all possible combinations of horizontal and vertical lines. We deliberately left out a few novel combinations of lines it has not seen together before, which are used to test the network to see if the network can correctly generalize. Each time a new network is run, the program automatically selects 10% (randomly) of the line combinations and put them in a Test table. 

* Click `Train` again, and then `Stop` once the network has reached 0 error. While viewing `Act` on the netview, click `TestTrial`, which will present one of the new combinations of lines it has never seen together before. Look at the output patterns. Step through a few more TestTrials. To get a broader sense of the performance across multiple networks you can just click `Train` and let it run through 10 networks with different initial weights and different permutations of training/test patterns. Switch to viewing the `RunPlot` tab, where you will see a graph of the network percent correct (PctCor) on the test data across each of the 10 networks (values close to 1.0 represent perfect 100% generalization and values close to 0 mean that it got none of the test patterns right).

> **Question 4.11:**  Report what you see in the output in the test trials and across runs. Does the network generalize its learning by reporting the correct combinations of lines? Consider why this might be in terms of the internal hidden representations that were learned by the hidden layer in the earlier question. 

* Now switch the learning rule from `ErrorDriven` to `Hebbian` and `Train` again. You should see in the `TrnEpcPlot` that the network does not learn the task, showing similar limitations of hebbian learning for arbitrary task learning as seen in earlier projects. Nevertheless, if you click on the hidden units and click `r.Wt` on the netview you should see that the hidden units exhibit similar learned representations of the lines to what you saw in `self_org`. Thus even though Hebbian learning fails to learn the output labeling task (ie it is not able to 'report' which lines it sees in the output), the internal representations that it develops are still sensitive to the independent components. 

* Let's see if we can leverage this learning to improve generalization. Switch the learning rule to `ErrorHebbIn`. This will maintain purely Hebbian learning (in the `LeabraPrjn`, setting `Learn.XCal` LLrn=1, MLrn=0, where L = amount of BCM long-term running average, M = error-driven medium-term) in the Input to Hidden projection, combined with pure Error-driven learning (LLrn=0, MLrn=1) in the connections between Hidden and Output. Click 'Train' and run a full set of 10 networks. Confirm first that the network can learn the training set (looking at `TrnEpcPlot` to see if the SSE goes down to zero). Then, look at the 'RunPlot' tab which will again display the percent correct for each network in the test phase. (You can also click TestTrial again to see if any individual network is generalizing in each trial). 

> **Question 4.12:** In general, does Hebbian learning in the hidden layer help the network perform better at generalizing to new items? Why or why not?  Consider more generally how the combination of learning rules might be useful for the brain.
 
 You can also check whether this new learning rule is capable of solving the Impossible problem (just switch `Pats` to `Impossible` and press `Train`. The network will run through the patterns and just use the first few units of input and output layers, as it does not need all the units that make up the lines.
